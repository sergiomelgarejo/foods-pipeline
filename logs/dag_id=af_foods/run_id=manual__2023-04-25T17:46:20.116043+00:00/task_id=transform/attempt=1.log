[2023-04-25 17:46:35,042] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: af_foods.transform manual__2023-04-25T17:46:20.116043+00:00 [queued]>
[2023-04-25 17:46:35,052] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: af_foods.transform manual__2023-04-25T17:46:20.116043+00:00 [queued]>
[2023-04-25 17:46:35,053] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-04-25 17:46:35,053] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2023-04-25 17:46:35,054] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-04-25 17:46:35,065] {taskinstance.py:1377} INFO - Executing <Task(_PythonDecoratedOperator): transform> on 2023-04-25 17:46:20.116043+00:00
[2023-04-25 17:46:35,070] {standard_task_runner.py:52} INFO - Started process 254 to run task
[2023-04-25 17:46:35,074] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'af_foods', 'transform', 'manual__2023-04-25T17:46:20.116043+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/af_foods.py', '--cfg-path', '/tmp/tmp6ljj_4fz', '--error-file', '/tmp/tmprd4l6_tq']
[2023-04-25 17:46:35,076] {standard_task_runner.py:80} INFO - Job 12: Subtask transform
[2023-04-25 17:46:35,141] {task_command.py:369} INFO - Running <TaskInstance: af_foods.transform manual__2023-04-25T17:46:20.116043+00:00 [running]> on host b016b1d76fa3
[2023-04-25 17:46:35,567] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=me
AIRFLOW_CTX_DAG_ID=af_foods
AIRFLOW_CTX_TASK_ID=transform
AIRFLOW_CTX_EXECUTION_DATE=2023-04-25T17:46:20.116043+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-04-25T17:46:20.116043+00:00
[2023-04-25 17:46:37,391] {logging_mixin.py:115} INFO - Foods df created.
[2023-04-25 17:46:37,642] {logging_mixin.py:115} INFO - Nutrients df created.
[2023-04-25 17:46:37,664] {python.py:173} INFO - Done. Returned value was: (       fdcId  ... foodCategoryId
0    2353623  ...            NaN
1    2341752  ...      2643175.0
2     167782  ...            NaN
3     171687  ...            NaN
4     171686  ...            NaN
..       ...  ...            ...
195  2344717  ...      2649105.0
196   171701  ...            NaN
197   173938  ...            NaN
198   171699  ...            NaN
199   171700  ...            NaN

[200 rows x 7 columns],          nutrientId                 nutrientName  ... foodNutrientId    fdcId
0              1003                      Protein  ...       28605004  2341752
1              1004            Total lipid (fat)  ...       28605005  2341752
2              1005  Carbohydrate, by difference  ...       28605006  2341752
3              1008                       Energy  ...       28605007  2341752
4              1018               Alcohol, ethyl  ...       28605008  2341752
...             ...                          ...  ...            ...      ...
1113852        1224                Glutamic acid  ...        1632420   171700
1113853        1225                      Glycine  ...        1632421   171700
1113854        1226                      Proline  ...        1632422   171700
1113855        1253                  Cholesterol  ...        1632423   171700
1113856        1114          Vitamin D (D2 + D3)  ...        1632424   171700

[1113857 rows x 9 columns])
[2023-04-25 17:46:37,706] {xcom.py:585} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config.
[2023-04-25 17:46:37,707] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2380, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 197, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 582, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2023-04-25 17:46:37,728] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=af_foods, task_id=transform, execution_date=20230425T174620, start_date=20230425T174635, end_date=20230425T174637
[2023-04-25 17:46:37,741] {standard_task_runner.py:97} ERROR - Failed to execute job 12 for task transform (Object of type DataFrame is not JSON serializable; 254)
[2023-04-25 17:46:37,825] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-04-25 17:46:37,873] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
